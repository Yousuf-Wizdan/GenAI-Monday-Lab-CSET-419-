# -*- coding: utf-8 -*-
"""GenAI-LAB-01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19x7A5CpvZMD4MXN_gxL6ZdeVOVMmZF7A

✅ STEP 1 – Install + Mount Drive
"""

!pip install -q diffusers transformers accelerate safetensors torchvision tqdm

from google.colab import drive
drive.mount('/content/drive')

"""✅ STEP 2 – Generate 20×20 = 400 Dog Images (Dataset Creation)"""

from huggingface_hub import login
login()

import torch
from diffusers import StableDiffusionPipeline
import os
from tqdm import tqdm

# -----------------------------
# Model Setup
# -----------------------------
model_id = "runwayml/stable-diffusion-v1-5"

pipe = StableDiffusionPipeline.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    safety_checker=None
).to("cuda")

pipe.enable_attention_slicing()

# -----------------------------
# 20 Dog Breeds
# -----------------------------
dog_breeds = [
    "golden retriever", "german shepherd", "labrador retriever", "beagle", "pug",
    "rottweiler", "doberman pinscher", "siberian husky", "french bulldog", "border collie",
    "chihuahua", "pomeranian", "great dane", "shih tzu", "boxer",
    "dachshund", "akita", "cocker spaniel", "bernese mountain dog", "australian shepherd"
]

images_per_breed = 20
output_dir = "/content/drive/MyDrive/dog_dataset"

os.makedirs(output_dir, exist_ok=True)

# -----------------------------
# Image Generation
# -----------------------------
for breed in dog_breeds:
    breed_dir = os.path.join(output_dir, breed.replace(" ", "_"))
    os.makedirs(breed_dir, exist_ok=True)

    print(f"Generating: {breed}")

    for i in tqdm(range(images_per_breed)):
        prompt = f"a high quality photo of a {breed}, ultra realistic, DSLR, sharp focus, 4k"

        generator = torch.Generator("cuda").manual_seed(i * 100 + hash(breed) % 1000)

        image = pipe(
            prompt,
            num_inference_steps=30,
            guidance_scale=7.5,
            generator=generator
        ).images[0]

        image.save(os.path.join(breed_dir, f"{breed.replace(' ', '_')}_{i}.png"))

print("✅ Dataset generation complete.")

"""✅ STEP 3 – Imports"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split

"""✅ STEP 4 – Transforms"""

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

"""✅ STEP 5 – Load Dataset"""

dataset_path = "/content/drive/MyDrive/dog_dataset"
dataset = datasets.ImageFolder(root=dataset_path, transform=transform)

print("Total images:", len(dataset))

"""✅ STEP 6 – Train / Val / Test Split (THIS is where your fix goes)"""

total_size = len(dataset)

train_size = int(0.7 * total_size)
val_size = int(0.15 * total_size)
test_size = total_size - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(
    dataset, [train_size, val_size, test_size]
)

print("Train:", len(train_dataset))
print("Val:", len(val_dataset))
print("Test:", len(test_dataset))

"""✅ STEP 7 – Create DataLoaders (THIS creates test_loader)"""

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

"""✅ STEP 6 – Model Setup"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 20)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0003)

"""✅ STEP 7 – Training Loop"""

epochs = 10

for epoch in range(epochs):
    # -------- TRAIN --------
    model.train()
    running_loss = 0.0
    train_correct = 0
    train_total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # Train accuracy
        _, predicted = torch.max(outputs, 1)
        train_total += labels.size(0)
        train_correct += (predicted == labels).sum().item()

    train_loss = running_loss / len(train_loader)
    train_accuracy = 100 * train_correct / train_total

    # -------- VALIDATION --------
    model.eval()
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    val_accuracy = 100 * val_correct / val_total

    print(
        f"Epoch [{epoch+1}/{epochs}] "
        f"| Train Loss: {train_loss:.4f} "
        f"| Train Acc: {train_accuracy:.2f}% "
        f"| Val Acc: {val_accuracy:.2f}%"
    )

print("✅ Training complete.")

"""✅ STEP 8 – Test Accuracy"""

model.eval()
test_correct = 0
test_total = 0

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        test_total += labels.size(0)
        test_correct += (predicted == labels).sum().item()

test_accuracy = 100 * test_correct / test_total
print(f"\n✅ Final Test Accuracy: {test_accuracy:.2f}%")